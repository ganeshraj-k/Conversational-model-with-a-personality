{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext==0.6\n",
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 720
        },
        "id": "eT0Tij2_q6br",
        "outputId": "158eadef-df19-4f3e-e918-b90d559dc7ec"
      },
      "id": "eT0Tij2_q6br",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchtext==0.6\n",
            "  Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6) (4.66.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6) (2.31.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6) (2.1.0+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6) (1.23.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6) (1.16.0)\n",
            "Collecting sentencepiece (from torchtext==0.6)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6) (2023.11.17)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchtext==0.6) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchtext==0.6) (1.3.0)\n",
            "Installing collected packages: sentencepiece, torchtext\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.16.0\n",
            "    Uninstalling torchtext-0.16.0:\n",
            "      Successfully uninstalled torchtext-0.16.0\n",
            "Successfully installed sentencepiece-0.1.99 torchtext-0.6.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torchtext"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06f11958",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06f11958",
        "outputId": "f46dd7d9-3855-4fbb-81e1-0f1f14977d71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "from torchtext.datasets import Multi30k\n",
        "from torchtext.data import Field, BucketIterator\n",
        "import numpy as np\n",
        "import spacy\n",
        "import random\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from itertools import chain\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset\n",
        "from torchtext.data import Example\n",
        "import torchtext\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import torch\n",
        "import spacy\n",
        "from torchtext.data.metrics import bleu_score\n",
        "import sys\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# additional functions\n",
        "\n",
        "\n",
        "def bleu(data, model, german, english, device):\n",
        "    targets = []\n",
        "    outputs = []\n",
        "\n",
        "    for example in data:\n",
        "        src = vars(example)[\"src\"]\n",
        "        trg = vars(example)[\"trg\"]\n",
        "\n",
        "        prediction = translate_sentence(model, src, german, english, device)\n",
        "        prediction = prediction[:-1]  # remove <eos> token\n",
        "\n",
        "        targets.append([trg])\n",
        "        outputs.append(prediction)\n",
        "\n",
        "    return bleu_score(outputs, targets)\n",
        "\n",
        "\n",
        "def save_checkpoint(state, filename=\"my_checkpoint.pth.tar\"):\n",
        "    print(\"=> Saving checkpoint\")\n",
        "    torch.save(state, filename)\n",
        "\n",
        "\n",
        "def load_checkpoint(checkpoint, model, optimizer):\n",
        "    print(\"=> Loading checkpoint\")\n",
        "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
        "\n",
        "\n",
        "\n",
        "def translate_sentence(model, sentence, german, english, device, max_length=50):\n",
        "    # print(sentence)\n",
        "\n",
        "    # sys.exit()\n",
        "\n",
        "\n",
        "    # Create tokens using spacy and everything in lower case (which is what our vocab is)\n",
        "    tokens = tokenizer_text(sentence)\n",
        "\n",
        "    # print(tokens)\n",
        "\n",
        "    # sys.exit()\n",
        "    # Add <SOS> and <EOS> in beginning and end respectively\n",
        "    tokens.insert(0, \"<sos>\")\n",
        "    tokens.append( \"<eos>\")\n",
        "\n",
        "    # Go through each german token and convert to an index\n",
        "    text_to_indices = [SRC.vocab.stoi[token] for token in tokens]\n",
        "\n",
        "    # Convert to Tensor\n",
        "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n",
        "\n",
        "    # Build encoder hidden, cell state\n",
        "    with torch.no_grad():\n",
        "        hidden, cell = model.encoder(sentence_tensor)\n",
        "\n",
        "    outputs = [TRG.vocab.stoi[\"<sos>\"]]\n",
        "\n",
        "    for _ in range(max_length):\n",
        "        previous_word = torch.LongTensor([outputs[-1]]).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output, hidden, cell = model.decoder(previous_word, hidden, cell)\n",
        "            best_guess = output.argmax(1).item()\n",
        "\n",
        "        outputs.append(best_guess)\n",
        "\n",
        "        # Model predicts it's the end of the sentence\n",
        "        if output.argmax(1).item() == TRG.vocab.stoi[\"<eos>\"]:\n",
        "            break\n",
        "\n",
        "    translated_sentence = [TRG.vocab.itos[idx] for idx in outputs]\n",
        "\n",
        "    # remove start token\n",
        "    return translated_sentence[1:]"
      ],
      "metadata": {
        "id": "GtwBlFY9y59Q"
      },
      "id": "GtwBlFY9y59Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vwfrxVJcq6Cm"
      },
      "id": "vwfrxVJcq6Cm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c4d0683",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c4d0683",
        "outputId": "e6683af3-181c-4565-c4ce-41d1839cf1ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6340, 2) (1057, 2) (1057, 2)\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"/content/Chandler_Bing_utterances.csv\")\n",
        "df.head(5)\n",
        "\n",
        "\n",
        "df_filtered = df[df.Interacted_with != \"Chandler Bing\"].copy()\n",
        "\n",
        "df_filtered.reset_index(drop = True)\n",
        "df_filtered.drop(columns = ['Interacted_with'], inplace = True)\n",
        "\n",
        "df_filtered.head()\n",
        "\n",
        "df_filtered.rename(columns = {'utterance_by_other' : 'src' , 'utterance_by_chandler':'trg'}, inplace = True)\n",
        "\n",
        "df_filtered['src'] = df_filtered['src'].astype('string')\n",
        "df_filtered['trg'] = df_filtered['src'].astype('string')\n",
        "\n",
        "df_filtered.fillna(\"\", inplace = True)\n",
        "\n",
        "\n",
        "df_train, df_temp = train_test_split( df_filtered, test_size = 0.25, random_state = 1)\n",
        "df_val, df_test = train_test_split(df_temp, test_size = 0.5, random_state = 1)\n",
        "print(df_train.shape, df_val.shape, df_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenizer_text(text):\n",
        "    sentences = sent_tokenize(text)\n",
        "    words = [word_tokenize(sentence) for sentence in sentences]\n",
        "    return list(chain(*words))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, dataframe, source_lang_field, target_lang_field):\n",
        "        self.dataframe = dataframe\n",
        "        self.src = source_lang_field\n",
        "        self.trg = target_lang_field\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        source_sentence = self.dataframe.iloc[idx][self.src]\n",
        "        target_sentence = self.dataframe.iloc[idx][self.trg]\n",
        "        return {\"src\": source_sentence, \"trg\": target_sentence}\n",
        "\n",
        "\n",
        "def process_data(dataset, src_field, trg_field):\n",
        "    # Create field structure\n",
        "    fields = [('src', src_field), ('trg', trg_field)]\n",
        "\n",
        "    # Convert each dictionary to a torchtext Example object\n",
        "    examples = [Example.fromlist([data['src'], data['trg']], fields) for data in dataset]\n",
        "\n",
        "    # Create a Dataset from the examples\n",
        "    return torchtext.data.Dataset(examples, fields=fields)"
      ],
      "metadata": {
        "id": "9jHvCE49rJjg"
      },
      "id": "9jHvCE49rJjg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5d0ea70",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5d0ea70",
        "outputId": "b0ff93e6-224e-46ec-f3d1-7ee8d8fbfd43"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2750"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "\n",
        "# Load English tokenizer, tagger, parser, NER and word vectors\n",
        "\n",
        "\n",
        "dataset_1 = TranslationDataset(df_filtered , 'src', 'trg')\n",
        "\n",
        "SRC = Field(tokenize=tokenizer_text, init_token='<sos>', eos_token='<eos>', lower=True)\n",
        "TRG = Field(tokenize=tokenizer_text, init_token='<sos>', eos_token='<eos>', lower=True)\n",
        "\n",
        "# Use this function to process your dataset\n",
        "processed_train_dataset = process_data(dataset_1, SRC, TRG)\n",
        "\n",
        "# Now build the vocabularies\n",
        "SRC.build_vocab(processed_train_dataset, min_freq=2)\n",
        "TRG.build_vocab(processed_train_dataset, min_freq=2)\n",
        "len(SRC.vocab)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = process_data(  TranslationDataset(df_train, 'src', 'trg')  ,SRC, TRG)\n",
        "valid_data = process_data(  TranslationDataset(df_val, 'src', 'trg')  ,SRC, TRG)\n",
        "test_data = process_data(  TranslationDataset(df_test, 'src', 'trg')  ,SRC, TRG)"
      ],
      "metadata": {
        "id": "-Ow08dIcsSlr"
      },
      "id": "-Ow08dIcsSlr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a679bbe4",
      "metadata": {
        "id": "a679bbe4"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.dropout = nn.Dropout(p)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (seq_length, N) where N is batch size\n",
        "\n",
        "        embedding = self.dropout(self.embedding(x))\n",
        "        # embedding shape: (seq_length, N, embedding_size)\n",
        "\n",
        "        outputs, (hidden, cell) = self.rnn(embedding)\n",
        "        # outputs shape: (seq_length, N, hidden_size)\n",
        "\n",
        "        return hidden, cell\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(\n",
        "        self, input_size, embedding_size, hidden_size, output_size, num_layers, p\n",
        "    ):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.dropout = nn.Dropout(p)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x, hidden, cell):\n",
        "        # x shape: (N) where N is for batch size, we want it to be (1, N), seq_length\n",
        "        # is 1 here because we are sending in a single word and not a sentence\n",
        "        x = x.unsqueeze(0)\n",
        "\n",
        "        embedding = self.dropout(self.embedding(x))\n",
        "        # embedding shape: (1, N, embedding_size)\n",
        "\n",
        "        outputs, (hidden, cell) = self.rnn(embedding, (hidden, cell))\n",
        "        # outputs shape: (1, N, hidden_size)\n",
        "\n",
        "        predictions = self.fc(outputs)\n",
        "\n",
        "        # predictions shape: (1, N, length_target_vocabulary) to send it to\n",
        "        # loss function we want it to be (N, length_target_vocabulary) so we're\n",
        "        # just gonna remove the first dim\n",
        "        predictions = predictions.squeeze(0)\n",
        "\n",
        "        return predictions, hidden, cell\n",
        "\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, source, target, teacher_force_ratio=0.5):\n",
        "        batch_size = source.shape[1]\n",
        "        target_len = target.shape[0]\n",
        "        target_vocab_size = len(TRG.vocab)\n",
        "\n",
        "        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n",
        "\n",
        "        hidden, cell = self.encoder(source)\n",
        "\n",
        "        # Grab the first input to the Decoder which will be <SOS> token\n",
        "        x = target[0]\n",
        "\n",
        "        for t in range(1, target_len):\n",
        "            # Use previous hidden, cell as context from encoder at start\n",
        "            output, hidden, cell = self.decoder(x, hidden, cell)\n",
        "\n",
        "            # Store next output prediction\n",
        "            outputs[t] = output\n",
        "\n",
        "            # Get the best word the Decoder predicted (index in the vocabulary)\n",
        "            best_guess = output.argmax(1)\n",
        "\n",
        "            # With probability of teacher_force_ratio we take the actual next word\n",
        "            # otherwise we take the word that the Decoder predicted it to be.\n",
        "            # Teacher Forcing is used so that the model gets used to seeing\n",
        "            # similar inputs at training and testing time, if teacher forcing is 1\n",
        "            # then inputs at test time might be completely different than what the\n",
        "            # network is used to. This was a long comment.\n",
        "            x = target[t] if random.random() < teacher_force_ratio else best_guess\n",
        "\n",
        "        return outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d63aef7f",
      "metadata": {
        "id": "d63aef7f"
      },
      "outputs": [],
      "source": [
        "num_epochs = 100\n",
        "learning_rate = 0.001\n",
        "batch_size = 64\n",
        "\n",
        "# Model hyperparameters\n",
        "load_model = False\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "input_size_encoder = len(SRC.vocab)\n",
        "input_size_decoder = len(TRG.vocab)\n",
        "output_size = len(TRG.vocab)\n",
        "encoder_embedding_size = 300\n",
        "decoder_embedding_size = 300\n",
        "hidden_size = 1024  # Needs to be the same for both RNN's\n",
        "num_layers = 2\n",
        "enc_dropout = 0.5\n",
        "dec_dropout = 0.5\n",
        "\n",
        "# Tensorboard to get nice loss plot\n",
        "writer = SummaryWriter(f\"runs/loss_plot\")\n",
        "step = 0\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size=batch_size,\n",
        "    sort_within_batch=True,\n",
        "    sort_key=lambda x: len(x.src),\n",
        "    device=device,\n",
        ")\n",
        "\n",
        "encoder_net = Encoder(\n",
        "    input_size_encoder, encoder_embedding_size, hidden_size, num_layers, enc_dropout\n",
        ").to(device)\n",
        "\n",
        "decoder_net = Decoder(\n",
        "    input_size_decoder,\n",
        "    decoder_embedding_size,\n",
        "    hidden_size,\n",
        "    output_size,\n",
        "    num_layers,\n",
        "    dec_dropout,\n",
        ").to(device)\n",
        "\n",
        "model = Seq2Seq(encoder_net, decoder_net).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "pad_idx = TRG.vocab.stoi[\"<pad>\"]\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
        "\n",
        "if load_model:\n",
        "    load_checkpoint(torch.load(\"my_checkpoint.pth.tar\"), model, optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cVROo-owzzhv"
      },
      "id": "cVROo-owzzhv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6afc2185",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6afc2185",
        "outputId": "2535900f-4630-4614-bf45-ff58aa02951e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 0 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'are', 'you', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 1 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'how', 'are', 'you', '<unk>', '?', '<unk>', '?', '<eos>']\n",
            "[Epoch 2 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'are', 'you', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 3 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'how', 'are', 'you', '<unk>', '?', '<unk>', '?', '<eos>']\n",
            "[Epoch 4 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'how', 'are', 'you', '<unk>', '?', '<unk>', '?', '<eos>']\n",
            "[Epoch 5 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'how', 'are', 'you', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 6 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'how', 'are', 'you', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 7 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'how', 'are', 'you', '<unk>', '?', '<unk>', '?', '<eos>']\n",
            "[Epoch 8 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'how', 'are', 'you', '<unk>', '?', '<unk>', '?', '<eos>']\n",
            "[Epoch 9 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'how', 'are', 'you', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 10 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'how', 'are', 'you', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 11 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'how', 'are', 'you', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 12 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'how', 'are', 'you', '?', '<unk>', '<unk>', '<unk>', '<eos>']\n",
            "[Epoch 13 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'how', 'are', 'you', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 14 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'how', 'are', 'you', '?', '<unk>', 'are', '<unk>', '<eos>']\n",
            "[Epoch 15 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'are', 'you', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 16 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'you', 'serious', '?', '<unk>', '<unk>', '<unk>', '<eos>']\n",
            "[Epoch 17 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'how', 'are', 'you', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 18 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'how', 'are', 'you', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 19 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'how', 'are', 'you', '<unk>', '?', '<unk>', '?', '<eos>']\n",
            "[Epoch 20 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'how', 'are', 'you', '?', '<unk>', '<unk>', '<unk>', '<eos>']\n",
            "[Epoch 21 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'how', 'are', 'you', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 22 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'are', 'you', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 23 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'are', 'you', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 24 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'are', 'you', '?', '<unk>', 'are', '<unk>', '<eos>']\n",
            "[Epoch 25 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'are', 'you', '?', '<unk>', '<unk>', '<unk>', '<eos>']\n",
            "[Epoch 26 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'are', 'you', '?', '<unk>', '<unk>', '<unk>', '<eos>']\n",
            "[Epoch 27 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'are', 'you', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 28 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'are', 'you', '?', '<unk>', 'hate', '<unk>', '<eos>']\n",
            "[Epoch 29 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'are', 'you', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 30 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'are', 'you', '?', '<unk>', '<unk>', '<unk>', '<eos>']\n",
            "[Epoch 31 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'are', 'you', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 32 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'how', 'are', 'you', '?', '<unk>', '<unk>', '<unk>', '<eos>']\n",
            "[Epoch 33 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'you', 'serious', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 34 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'you', 'serious', '?', '<unk>', '<unk>', '<unk>', '<eos>']\n",
            "[Epoch 35 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'you', 'serious', '?', '<unk>', '<unk>', '<unk>', '<eos>']\n",
            "[Epoch 36 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'you', '?', '<unk>', 'are', '<unk>', '?', '<eos>']\n",
            "[Epoch 37 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'you', '?', '<unk>', 'are', '<unk>', '?', '<eos>']\n",
            "[Epoch 38 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'how', 'are', 'you', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 39 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'are', 'you', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 40 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'are', 'you', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 41 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'are', 'you', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 42 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'you', '?', '<unk>', 'you', '<unk>', '?', '<eos>']\n",
            "[Epoch 43 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'you', '?', '<unk>', 'are', '<unk>', '?', '<eos>']\n",
            "[Epoch 44 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'are', 'you', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 45 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'are', 'you', '?', '<unk>', \"'\", '?', '<eos>']\n",
            "[Epoch 46 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'you', 'serious', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 47 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'you', 'serious', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 48 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'you', 'serious', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 49 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'are', 'you', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 50 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'are', 'you', '?', '<unk>', \"'\", '<unk>', '<eos>']\n",
            "[Epoch 51 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'are', 'you', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 52 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'you', 'serious', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 53 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'you', 'serious', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 54 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'how', 'are', 'you', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 55 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'you', 'serious', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 56 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'you', 'serious', '?', '<unk>', \"'s\", '<unk>', '<eos>']\n",
            "[Epoch 57 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'says', 'are', 'you', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 58 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'says', 'are', 'you', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 59 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'are', 'you', '?', '<unk>', '?', '<unk>', '<eos>']\n",
            "[Epoch 60 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'are', 'you', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 61 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'are', 'you', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 62 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'you', '?', '?', 'are', '<unk>', '?', '<eos>']\n",
            "[Epoch 63 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'you', 'serious', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 64 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'are', 'you', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 65 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'you', 'serious', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 66 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'are', 'you', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 67 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'are', 'you', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 68 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'you', 'serious', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 69 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'you', 'serious', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 70 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'you', 'serious', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 71 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'you', 'are', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 72 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'you', 'serious', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 73 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'you', 'serious', '?', '<unk>', 'are', '<unk>', '<eos>']\n",
            "[Epoch 74 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'you', 'serious', '?', '<unk>', 'you', '<unk>', '<eos>']\n",
            "[Epoch 75 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'you', 'serious', '?', '<unk>', 'are', '<unk>', '<eos>']\n",
            "[Epoch 76 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'you', 'serious', '?', '<unk>', 'are', '<unk>', '<eos>']\n",
            "[Epoch 77 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'you', 'serious', '?', '<unk>', 'are', '<unk>', '<eos>']\n",
            "[Epoch 78 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'are', 'you', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 79 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'you', 'serious', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 80 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'you', '?', '?', '<unk>', 'are', '<unk>', '<eos>']\n",
            "[Epoch 81 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'are', 'serious', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 82 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'are', 'you', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 83 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'says', 'are', 'you', '?', '<unk>', 'are', '<unk>', '<eos>']\n",
            "[Epoch 84 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'are', 'you', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 85 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'says', 'are', 'you', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 86 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'says', 'are', 'you', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 87 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'are', 'you', '?', '<unk>', \"'s\", '<unk>', '<eos>']\n",
            "[Epoch 88 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'are', 'you', '?', '<unk>', \"'s\", '?', '<eos>']\n",
            "[Epoch 89 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'you', 'serious', '?', '<unk>', 'hate', '<unk>', '<eos>']\n",
            "[Epoch 90 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'are', 'you', '?', '<unk>', \"'s\", '<unk>', '<eos>']\n",
            "[Epoch 91 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'are', 'you', '?', '<unk>', 'are', '?', '<eos>']\n",
            "[Epoch 92 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'are', 'you', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 93 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'you', 'are', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 94 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'you', '?', '<unk>', 'are', '<unk>', '?', '<eos>']\n",
            "[Epoch 95 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'you', '?', '<unk>', 'are', '<unk>', '?', '<eos>']\n",
            "[Epoch 96 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'are', 'you', '?', '<unk>', \"'\", '?', '<eos>']\n",
            "[Epoch 97 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'are', 'you', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 98 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'are', 'you', '?', '<unk>', '<unk>', '?', '<eos>']\n",
            "[Epoch 99 / 100]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['<unk>', 'are', 'are', 'you', '?', '<unk>', '<unk>', '?', '<eos>']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "sentence = \"Hello how are you? I am Joey\"\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"[Epoch {epoch} / {num_epochs}]\")\n",
        "\n",
        "    checkpoint = {\"state_dict\": model.state_dict(), \"optimizer\": optimizer.state_dict()}\n",
        "    save_checkpoint(checkpoint)\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    translated_sentence = translate_sentence(\n",
        "        model, sentence, SRC, TRG, device, max_length=50\n",
        "    )\n",
        "\n",
        "    print(f\"Translated example sentence: \\n {translated_sentence}\")\n",
        "\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for batch_idx, batch in enumerate(train_iterator):\n",
        "        # Get input and targets and get to cuda\n",
        "        inp_data = batch.src.to(device)\n",
        "        target = batch.trg.to(device)\n",
        "\n",
        "        # Forward prop\n",
        "        output = model(inp_data, target)\n",
        "\n",
        "        # Output is of shape (trg_len, batch_size, output_dim) but Cross Entropy Loss\n",
        "        # doesn't take input in that form. For example if we have MNIST we want to have\n",
        "        # output to be: (N, 10) and targets just (N). Here we can view it in a similar\n",
        "        # way that we have output_words * batch_size that we want to send in into\n",
        "        # our cost function, so we need to do some reshapin. While we're at it\n",
        "        # Let's also remove the start token while we're at it\n",
        "        output = output[1:].reshape(-1, output.shape[2])\n",
        "        target = target[1:].reshape(-1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        # Back prop\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip to avoid exploding gradient issues, makes sure grads are\n",
        "        # within a healthy range\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "\n",
        "        # Gradient descent step\n",
        "        optimizer.step()\n",
        "\n",
        "        # Plot to tensorboard\n",
        "        writer.add_scalar(\"Training loss\", loss, global_step=step)\n",
        "        step += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = bleu(test_data[1:100], model, SRC, TRG, device)\n",
        "print(f\"Bleu score {score*100:.2f}\")"
      ],
      "metadata": {
        "id": "qwKK0FNYz0Q6"
      },
      "id": "qwKK0FNYz0Q6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent = \"Hello Chandler I am Ross, who are you? Hello Hello\"\n",
        "\n",
        "translated_sentence = translate_sentence(\n",
        "        model, sent, SRC, TRG, device, max_length=50)\n",
        "\n",
        "translated_sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHhDnFBB7Sy2",
        "outputId": "1e880092-a7f5-43f3-d0c7-0d7cb2621fc6"
      },
      "id": "cHhDnFBB7Sy2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<unk>',\n",
              " '<unk>',\n",
              " '<unk>',\n",
              " 'mr.',\n",
              " '<unk>',\n",
              " ',',\n",
              " 'are',\n",
              " 'you',\n",
              " '<unk>',\n",
              " '<unk>',\n",
              " '<unk>',\n",
              " '?',\n",
              " '<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pytorchenv2",
      "language": "python",
      "name": "pytorchenv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}